{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[-122.23, 37.88, 41.0, 880.0, 129.0, 322.0, 126.0, 8.3252],\n",
       "  [-122.22, 37.86, 21.0, 7099.0, 1106.0, 2401.0, 1138.0, 8.3014],\n",
       "  [-122.24, 37.85, 52.0, 1467.0, 190.0, 496.0, 177.0, 7.2574]],\n",
       " [452600.0, 358500.0, 352100.0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)\n",
    "\n",
    "        # Indices of numerical features (excluding 'ocean_proximity' which is the last column)\n",
    "        feature_indices = list(range(8))  \n",
    "        target_index = 8  \n",
    "\n",
    "        X, Y = [], []\n",
    "\n",
    "        for row in reader:\n",
    "            try:\n",
    "                features = [float(row[i]) for i in feature_indices]\n",
    "                target = float(row[target_index])\n",
    "                X.append(features)\n",
    "                Y.append(target)\n",
    "            except ValueError:\n",
    "                # Skip rows with missing or non-numeric data\n",
    "                continue\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X, Y = load_data(r'C:\\Users\\VICTUS\\Downloads\\housing\\housing.csv')\n",
    "\n",
    "X[:3], Y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.21115537848605498,\n",
       "  0.5674814027630182,\n",
       "  0.7843137254901961,\n",
       "  0.02233073910168371,\n",
       "  0.019863438857852266,\n",
       "  0.008940833543541018,\n",
       "  0.020555829633284,\n",
       "  0.5396684183666433],\n",
       " [0.21215139442231049,\n",
       "  0.5653560042507968,\n",
       "  0.39215686274509803,\n",
       "  0.180502568798006,\n",
       "  0.17147734326505276,\n",
       "  0.06721040387903249,\n",
       "  0.18697582634435125,\n",
       "  0.5380270616957007],\n",
       " [0.21015936254980092,\n",
       "  0.5642933049946866,\n",
       "  1.0,\n",
       "  0.03726028790884582,\n",
       "  0.029329608938547486,\n",
       "  0.013817651840017937,\n",
       "  0.028942608123663872,\n",
       "  0.46602805478545123]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the features using min-max scaling\n",
    "def normalize_features(X):\n",
    "    num_features = len(X[0])\n",
    "    min_vals = [min(feature[i] for feature in X) for i in range(num_features)] #for each feature it generates minimum value\n",
    "    max_vals = [max(feature[i] for feature in X) for i in range(num_features)] # - - generates max value\n",
    "\n",
    "    normalized_X = []\n",
    "    for row in X:\n",
    "        normalized_row = [\n",
    "            (row[i] - min_vals[i]) / (max_vals[i] - min_vals[i]) if max_vals[i] != min_vals[i] else 0\n",
    "            for i in range(num_features)\n",
    "        ]\n",
    "        normalized_X.append(normalized_row)\n",
    "\n",
    "    return normalized_X\n",
    "\n",
    "# Normalize X\n",
    "X_normalized = normalize_features(X)\n",
    "\n",
    "# Display normalized features\n",
    "X_normalized[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: RMSE = 237028.05\n",
      "Epoch 10: RMSE = 117187.08\n",
      "Epoch 20: RMSE = 111889.96\n",
      "Epoch 30: RMSE = 110819.92\n",
      "Epoch 40: RMSE = 109877.68\n",
      "Epoch 50: RMSE = 108963.30\n",
      "Epoch 60: RMSE = 108073.53\n",
      "Epoch 70: RMSE = 107207.51\n",
      "Epoch 80: RMSE = 106364.47\n",
      "Epoch 90: RMSE = 105543.69\n",
      "Epoch 100: RMSE = 104744.53\n",
      "Epoch 110: RMSE = 103966.34\n",
      "Epoch 120: RMSE = 103208.55\n",
      "Epoch 130: RMSE = 102470.60\n",
      "Epoch 140: RMSE = 101751.94\n",
      "Epoch 150: RMSE = 101052.08\n",
      "Epoch 160: RMSE = 100370.53\n",
      "Epoch 170: RMSE = 99706.82\n",
      "Epoch 180: RMSE = 99060.51\n",
      "Epoch 190: RMSE = 98431.14\n",
      "Epoch 200: RMSE = 97818.31\n",
      "Epoch 210: RMSE = 97221.61\n",
      "Epoch 220: RMSE = 96640.64\n",
      "Epoch 230: RMSE = 96075.02\n",
      "Epoch 240: RMSE = 95524.36\n",
      "Epoch 250: RMSE = 94988.31\n",
      "Epoch 260: RMSE = 94466.51\n",
      "Epoch 270: RMSE = 93958.61\n",
      "Epoch 280: RMSE = 93464.26\n",
      "Epoch 290: RMSE = 92983.14\n",
      "Epoch 300: RMSE = 92514.93\n",
      "Epoch 310: RMSE = 92059.29\n",
      "Epoch 320: RMSE = 91615.93\n",
      "Epoch 330: RMSE = 91184.54\n",
      "Epoch 340: RMSE = 90764.81\n",
      "Epoch 350: RMSE = 90356.46\n",
      "Epoch 360: RMSE = 89959.20\n",
      "Epoch 370: RMSE = 89572.75\n",
      "Epoch 380: RMSE = 89196.83\n",
      "Epoch 390: RMSE = 88831.19\n",
      "Epoch 400: RMSE = 88475.54\n",
      "Epoch 410: RMSE = 88129.65\n",
      "Epoch 420: RMSE = 87793.24\n",
      "Epoch 430: RMSE = 87466.09\n",
      "Epoch 440: RMSE = 87147.95\n",
      "Epoch 450: RMSE = 86838.57\n",
      "Epoch 460: RMSE = 86537.74\n",
      "Epoch 470: RMSE = 86245.22\n",
      "Epoch 480: RMSE = 85960.79\n",
      "Epoch 490: RMSE = 85684.25\n",
      "Epoch 500: RMSE = 85415.36\n",
      "Epoch 510: RMSE = 85153.94\n",
      "Epoch 520: RMSE = 84899.78\n",
      "Epoch 530: RMSE = 84652.68\n",
      "Epoch 540: RMSE = 84412.44\n",
      "Epoch 550: RMSE = 84178.89\n",
      "Epoch 560: RMSE = 83951.83\n",
      "Epoch 570: RMSE = 83731.10\n",
      "Epoch 580: RMSE = 83516.50\n",
      "Epoch 590: RMSE = 83307.88\n",
      "Epoch 600: RMSE = 83105.06\n",
      "Epoch 610: RMSE = 82907.89\n",
      "Epoch 620: RMSE = 82716.20\n",
      "Epoch 630: RMSE = 82529.85\n",
      "Epoch 640: RMSE = 82348.67\n",
      "Epoch 650: RMSE = 82172.53\n",
      "Epoch 660: RMSE = 82001.27\n",
      "Epoch 670: RMSE = 81834.77\n",
      "Epoch 680: RMSE = 81672.88\n",
      "Epoch 690: RMSE = 81515.48\n",
      "Epoch 700: RMSE = 81362.42\n",
      "Epoch 710: RMSE = 81213.60\n",
      "Epoch 720: RMSE = 81068.88\n",
      "Epoch 730: RMSE = 80928.15\n",
      "Epoch 740: RMSE = 80791.29\n",
      "Epoch 750: RMSE = 80658.19\n",
      "Epoch 760: RMSE = 80528.74\n",
      "Epoch 770: RMSE = 80402.83\n",
      "Epoch 780: RMSE = 80280.36\n",
      "Epoch 790: RMSE = 80161.23\n",
      "Epoch 800: RMSE = 80045.34\n",
      "Epoch 810: RMSE = 79932.59\n",
      "Epoch 820: RMSE = 79822.90\n",
      "Epoch 830: RMSE = 79716.16\n",
      "Epoch 840: RMSE = 79612.30\n",
      "Epoch 850: RMSE = 79511.23\n",
      "Epoch 860: RMSE = 79412.87\n",
      "Epoch 870: RMSE = 79317.13\n",
      "Epoch 880: RMSE = 79223.94\n",
      "Epoch 890: RMSE = 79133.22\n",
      "Epoch 900: RMSE = 79044.90\n",
      "Epoch 910: RMSE = 78958.90\n",
      "Epoch 920: RMSE = 78875.17\n",
      "Epoch 930: RMSE = 78793.62\n",
      "Epoch 940: RMSE = 78714.20\n",
      "Epoch 950: RMSE = 78636.84\n",
      "Epoch 960: RMSE = 78561.47\n",
      "Epoch 970: RMSE = 78488.05\n",
      "Epoch 980: RMSE = 78416.50\n",
      "Epoch 990: RMSE = 78346.79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[117854.7609373931,\n",
       " -102686.47090500961,\n",
       " -113791.22640462495,\n",
       " 86730.55122233105,\n",
       " 50248.82736590588,\n",
       " 48882.11743852196,\n",
       " -7015.432180285033,\n",
       " 49908.32179708757,\n",
       " 503663.93219058565]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add bias term (intercept) to feature vectors\n",
    "def add_bias_term(X):\n",
    "    return [[1.0] + row for row in X]\n",
    "\n",
    "# Initialize weights\n",
    "def initialize_weights(n):\n",
    "    return [random.uniform(-0.5, 0.5) for _ in range(n)]\n",
    "\n",
    "# Predict function\n",
    "def predict(X, weights):\n",
    "    return [sum(w * x for w, x in zip(weights, row)) for row in X]\n",
    "def compute_mae(Y_true, Y_pred):\n",
    "    n = len(Y_true)\n",
    "    return sum(abs((yt - yp)) for yt, yp in zip(Y_true, Y_pred)) / n\n",
    "# Compute Mean Squared Error\n",
    "def compute_mse(Y_true, Y_pred):\n",
    "    n = len(Y_true)\n",
    "    return sum((yt - yp) ** 2 for yt, yp in zip(Y_true, Y_pred)) / n\n",
    "\n",
    "# Gradient Descent function\n",
    "def gradient_descent(X, Y, weights, lr=0.01, epochs=100): # lr = learning rate\n",
    "    n = len(Y)\n",
    "    for epoch in range(epochs):\n",
    "        predictions = predict(X, weights)\n",
    "        gradients = [0.0] * len(weights)\n",
    "\n",
    "        for i in range(len(weights)):\n",
    "            for j in range(n):\n",
    "                gradients[i] += (predictions[j] - Y[j]) * X[j][i]\n",
    "            gradients[i] /= n\n",
    "\n",
    "        # Update weights\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] -= lr * gradients[i]\n",
    "\n",
    "        # Print progress every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            mse = compute_mse(Y, predictions)\n",
    "            print(f\"Epoch {epoch}: RMSE = {math.sqrt(mse):.2f}\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Prepare data\n",
    "X_bias = add_bias_term(X_normalized)\n",
    "weights = initialize_weights(len(X_bias[0]))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_bias, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Train model\n",
    "trained_weights = gradient_descent(X_train, Y_train, weights, lr=0.1, epochs=1000)\n",
    "\n",
    "trained_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE in trained data = 78278.83549430076\t\tRMSE in test data = 76758.50987693858\n",
      "MAE in trained data = 58959.901828312955\t\t\tMAE in test data = 57709.98643723191\n",
      "RMSE in Y_test, y_pred_train data = 135232.75938375504\t\t\tRMSE in Y_train, y_pre_test data = 68896.1475800677\n",
      "MAE in Y_test, y_pred_train data = 104870.13175988315\t\t\tMAE in Y_train, y_pre_test data = 26663.884249816067\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = predict(X_train, trained_weights)\n",
    "y_pred_test = predict(X_test, trained_weights)\n",
    "mse_train = compute_mse(Y_train, y_pred_train)\n",
    "mse_test = compute_mse(Y_test, y_pred_test)\n",
    "print(f\"RMSE in trained data = {math.sqrt(mse_train)}\\t\\tRMSE in test data = {math.sqrt(mse_test)}\")\n",
    "mae_train = compute_mae(Y_train, y_pred_train)\n",
    "mae_test = compute_mae(Y_test, y_pred_test)\n",
    "print(f\"MAE in trained data = {(mae_train)}\\t\\t\\tMAE in test data = {(mae_test)}\")\n",
    "mae1 = compute_mae(Y_test, y_pred_train)\n",
    "mae2 = compute_mae(Y_train, y_pred_test)\n",
    "mse1 = compute_mse(Y_test, y_pred_train)\n",
    "mse2 = compute_mse(Y_train, y_pred_test)\n",
    "print(f\"RMSE in Y_test, y_pred_train data = {math.sqrt(mse1)}\\t\\t\\tRMSE in Y_train, y_pre_test data = {math.sqrt(mse2)}\")\n",
    "print(f\"MAE in Y_test, y_pred_train data = {(mae1)}\\t\\t\\tMAE in Y_train, y_pre_test data = {(mae2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
